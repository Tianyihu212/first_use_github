{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323cb2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "torch.cuda.empty_cache()\n",
    "import boto3\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1810245",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID'] = 'ACCOUNT'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'PASSWORD'\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "def read_image_from_s3(key):\n",
    "    bucket = s3.Bucket('masterarbeit125255aa')\n",
    "    img = bucket.Object(key).get().get('Body').read()\n",
    "    img = cv2.imdecode(np.asarray(bytearray(img)), cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "\n",
    "def read_csv_from_s3(stage):\n",
    "\n",
    "    if stage == 'public':\n",
    "        df = pd.read_csv('s3://masterarbeit125255aa/data/train/public_tianyi.csv')\n",
    "    elif stage == 'private':\n",
    "        df = pd.read_csv('s3://masterarbeit125255aa/data/train/private_tianyi.csv')\n",
    "    elif stage == 'public_private':\n",
    "        df = pd.read_csv('s3://masterarbeit125255aa/data/train/public_private.csv')\n",
    "    elif stage == 'index':\n",
    "        df = pd.read_csv('s3://masterarbeit125255aa/data/train/index_tianyi.csv')\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'not supported stage{stage}')\n",
    "    return df\n",
    "\n",
    "class SiameseGLDV2(Dataset):\n",
    "\n",
    "    def __init__(self, stage: str):\n",
    "\n",
    "        self.df = read_csv_from_s3(stage)\n",
    "        self.df.drop(self.df.filter(regex=\"Unname\"), axis=1, inplace=True)\n",
    "        self.label_list = self.df.landmark_id.tolist()\n",
    "        self.namelist = [i.split('\\\\')[-1] for i in self.df.anchor.tolist()]\n",
    "        self.s3 = boto3.resource('s3')\n",
    "        if stage == 'index':\n",
    "            self.s3path = 'data/train/train_compress'\n",
    "        else:\n",
    "            self.s3path = 'data/test'\n",
    "        self.my_transformer = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.df.iloc[index]['landmark_id']\n",
    "        anchor = self.df.iloc[index]['anchor'].split('\\\\')\n",
    "        anchor_class = anchor[1]\n",
    "        anchor_filen = anchor[2]\n",
    "        anchor_image = self.s3path + '/' + anchor_class + '/' + anchor_filen\n",
    "        anchor_im = read_image_from_s3(anchor_image)\n",
    "        transformed_anchor_im = self.my_transformer(anchor_im)\n",
    "        return label, transformed_anchor_im , anchor_im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a28002d",
   "metadata": {},
   "source": [
    "# Hier is index global feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb109ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "\n",
    "def batch(iterable, n=BATCH_SIZE):\n",
    "    l = len(iterable.df)\n",
    "    for ndx in range(0, l, n):\n",
    "        imgs = []\n",
    "        for i in range(ndx,min(ndx + n, l)):\n",
    "            _,img,_ = iterable.__getitem__(i)\n",
    "            imgs.append(img.unsqueeze(0))\n",
    "        print(len(imgs))\n",
    "        ims = torch.vstack((imgs)).to(device)\n",
    "        yield ims\n",
    "\n",
    "def extract_global_features(model, dataset, stage='index'):\n",
    "    \"\"\"Save BATCH_SIZE embeddings into npy.\"\"\"\n",
    "    BATCH_IDX = 0\n",
    "    with torch.inference_mode():\n",
    "        for batch_imgs in batch(dataset):\n",
    "            print(f'current batch is {BATCH_IDX}')\n",
    "            embed = model.extract_features(batch_imgs)\n",
    "            embed = embed.cpu().detach().numpy()\n",
    "            embed_np = [i.flatten() for i in embed]\n",
    "            with open(SAVE_PATH + stage + '/' + str(BATCH_IDX).zfill(3) + '.npy', 'wb') as f:\n",
    "                np.save(f, np.array(embed_np))\n",
    "            BATCH_IDX += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a128261",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = 'out/'\n",
    "\n",
    "device='cuda'\n",
    "index_dataset = SiameseGLDV2('index')\n",
    "test_dataset = SiameseGLDV2('public_private')\n",
    "\n",
    "model = EfficientNet.from_pretrained(\"efficientnet-b0\").to(device)\n",
    "model.eval()\n",
    "extract_global_features(model, index_dataset,  'index')\n",
    "extract_global_features(model, test_dataset, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e21bb8",
   "metadata": {},
   "source": [
    "## 000.npy - 199.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49960f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_at_k(y_true, y_denominator, y_pred):\n",
    "    assert isinstance(y_true, np.ndarray) and isinstance(y_pred, np.ndarray)\n",
    "    assert y_true.ndim == 2 and y_pred.ndim == 2\n",
    "\n",
    "    k = y_pred.shape[1]\n",
    "    is_correct_list = []\n",
    "\n",
    "    for i in range(y_true.shape[1]):\n",
    "        is_correct = y_true[:, i][:, np.newaxis] == y_pred\n",
    "        is_correct_list.append(is_correct)\n",
    "    is_correct_mat = np.logical_or.reduce(np.array(is_correct_list))\n",
    "\n",
    "    cumsum_mat = np.apply_along_axis(np.cumsum, axis=1, arr=is_correct_mat)\n",
    "    arange_mat = np.expand_dims(np.arange(1, k + 1), axis=0)\n",
    "    ap_100_list = np.sum((cumsum_mat / arange_mat) * is_correct_mat, axis=1) / y_denominator\n",
    "    ap_100_list[ap_100_list > 1] = 1\n",
    "\n",
    "    return np.mean(ap_100_list), ap_100_list\n",
    "\n",
    "def list_to_array (x):\n",
    "    dff = pd.concat([pd.DataFrame({'{}'.format(index):labels}) for index,labels in enumerate(string_to_list(x))],axis=1)\n",
    "    return dff.fillna(0).values.T.astype(int)\n",
    "\n",
    "def string_to_list(x):\n",
    "    res = []\n",
    "    for a in x:\n",
    "        tmp = a.split(' ')\n",
    "        tmp2= [int(i) for i in tmp]\n",
    "        res.append(tmp2)\n",
    "    return res\n",
    "\n",
    "def index_to_label(index_array,label_list):\n",
    "    res = []\n",
    "    for i in range(len(index_array)):\n",
    "        res.append(label_list[index_array[i].astype(int)])\n",
    "    return np.array(res)\n",
    "\n",
    "def comt_denominater(y_true,y_pred):\n",
    "    res = []\n",
    "    for idx,i in enumerate(y_true):\n",
    "        count = 0\n",
    "        for j in i:\n",
    "            count += list(y_pred[idx]).count(j)\n",
    "        res.append(count)\n",
    "    res = np.array(res)\n",
    "    res[res==0] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d844971",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "class NN:\n",
    "    def __init__(self, batch_size=BATCH_SIZE, dim=512):\n",
    "        self.array = np.empty((0, dim))\n",
    "        self.id = []\n",
    "        self.score = np.empty((0, batch_size))\n",
    "\n",
    "    def add_item(self, item):\n",
    "        if item.ndim == 1:\n",
    "            item = item[np.newaxis,:]\n",
    "        self.array = item\n",
    "\n",
    "    def search(self, search_item, top_k=100):\n",
    "        self.res = cosine_similarity(self.array, search_item)\n",
    "        self.score = np.concatenate((self.score ,self.res),axis=0)\n",
    "        self.rank = self.res[:,0].argsort()[::-1][:top_k]\n",
    "\n",
    "    def update(self):\n",
    "        self.array = np.array([self.array[i] for i in self.rank])\n",
    "        self.id = [self.id[i] for i in self.rank]\n",
    "\n",
    "    def get_top_k(self, top_k=100):\n",
    "        return np.argsort(-self.score, axis= 0)[:top_k,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc96e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dataset = SiameseGLDV2('index')\n",
    "test_dataset = SiameseGLDV2('public_private')\n",
    "\n",
    "npy_list_index = sorted(glob.glob('out/index/*.npy'))\n",
    "npy_list_test = sorted(glob.glob('out/test/*.npy'))\n",
    "images = []\n",
    "score_list = []\n",
    "\n",
    "for ind,npy_test_path in tqdm(enumerate(npy_list_test)):\n",
    "    aps = []\n",
    "    npy_test = np.load(npy_test_path)\n",
    "    indexer = NN(dim=1280*7*7, batch_size=npy_test.shape[0])\n",
    "    for i,npy_index_path in tqdm(enumerate(npy_list_index)):\n",
    "        npy_index = np.load(npy_index_path)\n",
    "        indexer.add_item(npy_index)\n",
    "        indexes = indexer.search(npy_test)\n",
    "    top_k_array = indexer.get_top_k()\n",
    "\n",
    "    y_true = list_to_array(test_dataset.label_list[ind*BATCH_SIZE:min((ind+1)*BATCH_SIZE, len(test_dataset.label_list))])\n",
    "    y_pred = index_to_label(top_k_array.T,np.array(index_dataset.label_list))\n",
    "    map_100,ap_list = map_at_k(y_true= y_true,\n",
    "             y_denominator= comt_denominater(y_true, y_pred),\n",
    "             y_pred= y_pred)\n",
    "    \n",
    "    aps.extend(ap_list)\n",
    "    score_list.extend(list(np.sort(indexer.score, axis=0)[-1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e9bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_k_array[:,0])\n",
    "print(-np.sort(-indexer.score, axis=0)[:100,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baedc739",
   "metadata": {},
   "outputs": [],
   "source": [
    "top k image of first query image\n",
    "[14504 47536 18644 43736 75480 14519 81534 73586 70895 72316 18623 83840\n",
    " 13294 82929 21267 14500 74674 27915 81898 35572 69159 83546 63602 33261\n",
    " 58871 10561 57898  8168  1175 77246 27914 75431 35857 55351  2635 38369\n",
    " 32829 71297 57583 78443 49462 29161 15876 49800 43737 78856 23063 38355\n",
    " 79096 12883 27126 65356 23695  9800 79094 39211  9216 34398 21268 77864\n",
    " 78652 75433 73588 68733 13445 88561 56412 96758 38363 77410 24919 61989\n",
    " 72317 22326 11865 18355 42789 60493 45976  1459 14739 49801 33206 71841\n",
    " 52752 35784 26040 28580 16611 27259 85051 38371 61988 63137 69141 47534\n",
    " 93836 80475 54062 55326]\n",
    "cosine similary\n",
    "[0.42445731 0.42254734 0.4198465  0.40426522 0.39979428 0.39052811\n",
    " 0.38588095 0.38452125 0.36647618 0.36147875 0.35442877 0.35082251\n",
    " 0.34764612 0.34743255 0.34553725 0.3427453  0.34068626 0.33792084\n",
    " 0.33552909 0.33410934 0.33327612 0.33082718 0.3260178  0.32338801\n",
    " 0.31944689 0.31682131 0.31613293 0.31523979 0.31228456 0.31199259\n",
    " 0.31029612 0.30850211 0.30778471 0.30773336 0.3046695  0.30431691\n",
    " 0.30350095 0.30320835 0.30281579 0.30151001 0.30040783 0.30040491\n",
    " 0.29998979 0.29889715 0.29859236 0.29551837 0.29544222 0.29460022\n",
    " 0.29416415 0.29407382 0.29201961 0.29159325 0.29109785 0.29054362\n",
    " 0.28978673 0.28872064 0.28865123 0.28807366 0.28637445 0.28631157\n",
    " 0.28621984 0.28541684 0.28477892 0.28386804 0.28284135 0.28166395\n",
    " 0.28079492 0.28076956 0.28013963 0.27968758 0.27917382 0.27838394\n",
    " 0.27830783 0.277899   0.27706721 0.27689159 0.27631074 0.27618903\n",
    " 0.27558699 0.2741988  0.27390873 0.27379748 0.27373117 0.27301171\n",
    " 0.27196723 0.27196717 0.27176923 0.27165937 0.27116722 0.27068016\n",
    " 0.26954094 0.26909375 0.26893041 0.26876268 0.26841876 0.26837063\n",
    " 0.26766989 0.26755553 0.2673935  0.26726878]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a90328",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score_list)\n",
    "print('The map@100 is : {}'.format(np.mean(aps)))\n",
    "print('The max ap@100 is : {}'.format(np.max(aps)))\n",
    "print('The min ap@100 is : {}'.format(np.min(aps)))\n",
    "print('The max cos similarity is : {}'.format(max(score_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d7fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "The map@100 is : 0.22316579233875491\n",
    "The max ap@100 is : 1.0\n",
    "The min ap@100 is : 0.0\n",
    "The max cos similarity is : 0.8267913460731506"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
